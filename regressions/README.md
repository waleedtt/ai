# AI Study
AI study

## Regressions
* Simple Linear Regression

Simple linear regression is a statistical method used to examine the relationship between two continuous variables: one independent variable (predictor) and one dependent variable (response). The primary goal is to model the relationship between these variables by fitting a linear equation to the observed data.

y= b0 + b1X
dependent variable = y-intercept(constant) + slope coefficient independent

* Multiple Linear Regression

Multiple linear regression refers to a statistical technique that is used to predict the outcome of a variable based on the value of two or more variables. It is sometimes known simply as multiple regression, and it is an extension of linear regression. The variable that we want to predict is known as the dependent variable, while the variables we use to predict the value of the dependent variable are known as independent or explanatory variables.
Y = b0 + b1X1 + b2X2

Where:

y is the dependent or predicted variable
b0 is the y-intercept, i.e., the value of y when both xi and x2 are 0.
b1 and b2 are the regression coefficients representing the change in y relative to a one-unit change in xi1 and xi2, respectively.


* Polynomial Regression

Polynomial regression is an extension of simple linear regression that allows for modeling the relationship between the independent variable (X) and the dependent variable (Y) as an nth degree polynomial. This approach can capture more complex, non-linear relationships that a simple linear regression might miss.


* Support Vector Regression


Support Vector Regression (SVR) is a type of machine learning model that applies the principles of Support Vector Machines (SVM) to regression problems. Unlike traditional linear regression, SVR uses a margin of tolerance (epsilon) and kernel functions to handle non-linear relationships between the independent variable (features) and the dependent variable (target).